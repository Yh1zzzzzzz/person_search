2026-01-02 22:18:10,248 IRRA INFO: Using 1 GPUs
2026-01-02 22:18:10,248 IRRA INFO: Namespace(local_rank=0
 name='t5_retrieval_gen_reuse'
 output_dir='logs/CUHK-PEDES/20260102_221810_t5_retrieval_gen_reuse'
 log_period=100
 eval_period=1
 val_dataset='test'
 resume=False
 resume_ckpt_file=''
 backbone='t5gemma2'
 hf_model_name_or_path='T5_270M_Base'
 pretrain_choice='ViT-B/16'
 temperature=0.02
 img_aug=False
 cmt_depth=4
 masked_token_rate=0.8
 masked_token_unchanged_rate=0.1
 lr_factor=5.0
 MLM=False
 loss_names='sdm+id+gen'
 mlm_loss_weight=1.0
 id_loss_weight=1.0
 gen_loss_weight=1.0
 gen_prompt='Caption'
 gen_prompt_length=32
 feature_dim=1024
 t5_image_size=448
 img_size=(384
 128)
 stride_size=16
 text_length=77
 vocab_size=49408
 mm_max_length=512
 optimizer='Adam'
 lr=1e-05
 bias_lr_factor=2.0
 momentum=0.9
 weight_decay=4e-05
 weight_decay_bias=0.0
 alpha=0.9
 beta=0.999
 num_epoch=60
 milestones=(20
 50)
 gamma=0.1
 warmup_factor=0.1
 warmup_epochs=5
 warmup_method='linear'
 lrscheduler='cosine'
 target_lr=0
 power=0.9
 dataset_name='CUHK-PEDES'
 sampler='random'
 num_instance=4
 root_dir='training_data'
 batch_size=32
 test_batch_size=512
 num_workers=10
 training=True
 amp=True
 amp_dtype='bf16'
 grad_accum_steps=2
 max_grad_norm=1.0
 gradient_checkpointing=True
 reuse_mm_encoder_for_image=True
 tokenizers_parallelism='false'
 distributed=False)
2026-01-02 22:18:10,738 IRRA.dataset INFO: => CUHK-PEDES Images and Captions are loaded
2026-01-02 22:18:10,738 IRRA.dataset INFO: CUHKPEDES Dataset statistics:
2026-01-02 22:18:10,738 IRRA.dataset INFO: 
+--------+-------+--------+----------+
| subset |  ids  | images | captions |
+--------+-------+--------+----------+
| train  | 11003 | 34054  |  68126   |
|  test  |  1000 |  3074  |   6156   |
|  val   |  1000 |  3078  |   6158   |
+--------+-------+--------+----------+
2026-01-02 22:18:18,832 IRRA.dataset INFO: using random sampler
2026-01-02 22:18:19,657 IRRA INFO: Total params: 795M
2026-01-02 22:18:20,397 IRRA.train INFO: start training
2026-01-02 22:26:35,623 IRRA.train INFO: Epoch[1] Iteration[100/2129], loss: 20.6503, sdm_loss: 7.1195, id_loss: 10.2785, gen_loss: 3.2523, Base Lr: 1.00e-06
2026-01-02 22:34:49,871 IRRA.train INFO: Epoch[1] Iteration[200/2129], loss: 20.6050, sdm_loss: 7.1121, id_loss: 10.2496, gen_loss: 3.2433, Base Lr: 1.00e-06
2026-01-02 22:43:04,587 IRRA.train INFO: Epoch[1] Iteration[300/2129], loss: 20.5591, sdm_loss: 7.1058, id_loss: 10.2231, gen_loss: 3.2301, Base Lr: 1.00e-06
2026-01-02 22:51:18,951 IRRA.train INFO: Epoch[1] Iteration[400/2129], loss: 20.5369, sdm_loss: 7.0998, id_loss: 10.2125, gen_loss: 3.2247, Base Lr: 1.00e-06
2026-01-02 22:59:33,782 IRRA.train INFO: Epoch[1] Iteration[500/2129], loss: 20.5095, sdm_loss: 7.0937, id_loss: 10.1996, gen_loss: 3.2162, Base Lr: 1.00e-06
2026-01-02 23:07:48,771 IRRA.train INFO: Epoch[1] Iteration[600/2129], loss: 20.4824, sdm_loss: 7.0880, id_loss: 10.1892, gen_loss: 3.2053, Base Lr: 1.00e-06
2026-01-02 23:16:03,816 IRRA.train INFO: Epoch[1] Iteration[700/2129], loss: 20.4625, sdm_loss: 7.0845, id_loss: 10.1809, gen_loss: 3.1971, Base Lr: 1.00e-06
2026-01-02 23:24:19,130 IRRA.train INFO: Epoch[1] Iteration[800/2129], loss: 20.4345, sdm_loss: 7.0790, id_loss: 10.1680, gen_loss: 3.1875, Base Lr: 1.00e-06
2026-01-02 23:32:34,242 IRRA.train INFO: Epoch[1] Iteration[900/2129], loss: 20.4118, sdm_loss: 7.0756, id_loss: 10.1593, gen_loss: 3.1769, Base Lr: 1.00e-06
2026-01-02 23:40:48,070 IRRA.train INFO: Epoch[1] Iteration[1000/2129], loss: 20.3940, sdm_loss: 7.0735, id_loss: 10.1496, gen_loss: 3.1709, Base Lr: 1.00e-06
2026-01-02 23:49:02,477 IRRA.train INFO: Epoch[1] Iteration[1100/2129], loss: 20.3761, sdm_loss: 7.0704, id_loss: 10.1414, gen_loss: 3.1643, Base Lr: 1.00e-06
2026-01-02 23:57:17,933 IRRA.train INFO: Epoch[1] Iteration[1200/2129], loss: 20.3606, sdm_loss: 7.0677, id_loss: 10.1345, gen_loss: 3.1584, Base Lr: 1.00e-06
2026-01-03 00:05:32,619 IRRA.train INFO: Epoch[1] Iteration[1300/2129], loss: 20.3417, sdm_loss: 7.0650, id_loss: 10.1262, gen_loss: 3.1505, Base Lr: 1.00e-06
2026-01-03 00:13:47,411 IRRA.train INFO: Epoch[1] Iteration[1400/2129], loss: 20.3263, sdm_loss: 7.0626, id_loss: 10.1200, gen_loss: 3.1437, Base Lr: 1.00e-06
2026-01-03 00:22:03,042 IRRA.train INFO: Epoch[1] Iteration[1500/2129], loss: 20.3139, sdm_loss: 7.0603, id_loss: 10.1143, gen_loss: 3.1393, Base Lr: 1.00e-06
2026-01-03 00:30:16,191 IRRA.train INFO: Epoch[1] Iteration[1600/2129], loss: 20.3006, sdm_loss: 7.0582, id_loss: 10.1089, gen_loss: 3.1336, Base Lr: 1.00e-06
2026-01-03 00:38:31,453 IRRA.train INFO: Epoch[1] Iteration[1700/2129], loss: 20.2879, sdm_loss: 7.0566, id_loss: 10.1023, gen_loss: 3.1291, Base Lr: 1.00e-06
2026-01-03 00:46:46,598 IRRA.train INFO: Epoch[1] Iteration[1800/2129], loss: 20.2767, sdm_loss: 7.0554, id_loss: 10.0965, gen_loss: 3.1248, Base Lr: 1.00e-06
2026-01-03 00:55:02,532 IRRA.train INFO: Epoch[1] Iteration[1900/2129], loss: 20.2670, sdm_loss: 7.0541, id_loss: 10.0922, gen_loss: 3.1208, Base Lr: 1.00e-06
2026-01-03 01:03:16,526 IRRA.train INFO: Epoch[1] Iteration[2000/2129], loss: 20.2580, sdm_loss: 7.0526, id_loss: 10.0889, gen_loss: 3.1166, Base Lr: 1.00e-06
2026-01-03 01:11:31,459 IRRA.train INFO: Epoch[1] Iteration[2100/2129], loss: 20.2498, sdm_loss: 7.0513, id_loss: 10.0857, gen_loss: 3.1128, Base Lr: 1.00e-06
2026-01-03 01:13:54,973 IRRA.train INFO: Epoch 1 done. Time per batch: 4.948[s] Speed: 6.5[samples/s]
2026-01-03 01:13:54,974 IRRA.train INFO: Validation Results - Epoch: 1
2026-01-03 01:15:54,403 IRRA.eval INFO: 
+------+-------+-------+-------+-------+-------+
| task |   R1  |   R5  |  R10  |  mAP  |  mINP |
+------+-------+-------+-------+-------+-------+
| t2i  | 0.114 | 0.520 | 1.105 | 0.403 | 0.219 |
+------+-------+-------+-------+-------+-------+
2026-01-03 01:24:16,288 IRRA.train INFO: Epoch[2] Iteration[100/2129], loss: 19.9017, sdm_loss: 7.0119, id_loss: 9.9624, gen_loss: 2.9274, Base Lr: 2.80e-06
2026-01-03 01:32:30,309 IRRA.train INFO: Epoch[2] Iteration[200/2129], loss: 19.6403, sdm_loss: 7.0033, id_loss: 9.9077, gen_loss: 2.7292, Base Lr: 2.80e-06
2026-01-03 01:40:44,464 IRRA.train INFO: Epoch[2] Iteration[300/2129], loss: 19.4548, sdm_loss: 6.9968, id_loss: 9.8731, gen_loss: 2.5849, Base Lr: 2.80e-06
2026-01-03 01:48:59,514 IRRA.train INFO: Epoch[2] Iteration[400/2129], loss: 19.3329, sdm_loss: 6.9934, id_loss: 9.8417, gen_loss: 2.4978, Base Lr: 2.80e-06
2026-01-03 01:57:14,338 IRRA.train INFO: Epoch[2] Iteration[500/2129], loss: 19.2557, sdm_loss: 6.9908, id_loss: 9.8203, gen_loss: 2.4445, Base Lr: 2.80e-06
2026-01-03 02:05:29,320 IRRA.train INFO: Epoch[2] Iteration[600/2129], loss: 19.1933, sdm_loss: 6.9887, id_loss: 9.7996, gen_loss: 2.4050, Base Lr: 2.80e-06
2026-01-03 02:13:43,704 IRRA.train INFO: Epoch[2] Iteration[700/2129], loss: 19.1460, sdm_loss: 6.9862, id_loss: 9.7847, gen_loss: 2.3751, Base Lr: 2.80e-06
2026-01-03 02:21:58,095 IRRA.train INFO: Epoch[2] Iteration[800/2129], loss: 19.1056, sdm_loss: 6.9844, id_loss: 9.7697, gen_loss: 2.3516, Base Lr: 2.80e-06
2026-01-03 02:30:12,884 IRRA.train INFO: Epoch[2] Iteration[900/2129], loss: 19.0710, sdm_loss: 6.9829, id_loss: 9.7565, gen_loss: 2.3316, Base Lr: 2.80e-06
2026-01-03 02:38:27,416 IRRA.train INFO: Epoch[2] Iteration[1000/2129], loss: 19.0432, sdm_loss: 6.9811, id_loss: 9.7460, gen_loss: 2.3161, Base Lr: 2.80e-06
2026-01-03 02:46:42,023 IRRA.train INFO: Epoch[2] Iteration[1100/2129], loss: 19.0200, sdm_loss: 6.9802, id_loss: 9.7366, gen_loss: 2.3033, Base Lr: 2.80e-06
2026-01-03 02:54:56,068 IRRA.train INFO: Epoch[2] Iteration[1200/2129], loss: 18.9945, sdm_loss: 6.9784, id_loss: 9.7251, gen_loss: 2.2910, Base Lr: 2.80e-06
2026-01-03 03:03:11,022 IRRA.train INFO: Epoch[2] Iteration[1300/2129], loss: 18.9755, sdm_loss: 6.9771, id_loss: 9.7161, gen_loss: 2.2823, Base Lr: 2.80e-06
2026-01-03 03:11:25,120 IRRA.train INFO: Epoch[2] Iteration[1400/2129], loss: 18.9549, sdm_loss: 6.9764, id_loss: 9.7062, gen_loss: 2.2724, Base Lr: 2.80e-06
2026-01-03 03:19:39,153 IRRA.train INFO: Epoch[2] Iteration[1500/2129], loss: 18.9376, sdm_loss: 6.9754, id_loss: 9.6984, gen_loss: 2.2639, Base Lr: 2.80e-06
2026-01-03 03:27:53,573 IRRA.train INFO: Epoch[2] Iteration[1600/2129], loss: 18.9229, sdm_loss: 6.9743, id_loss: 9.6913, gen_loss: 2.2572, Base Lr: 2.80e-06
2026-01-03 03:36:08,621 IRRA.train INFO: Epoch[2] Iteration[1700/2129], loss: 18.9090, sdm_loss: 6.9733, id_loss: 9.6857, gen_loss: 2.2499, Base Lr: 2.80e-06
2026-01-03 03:44:22,792 IRRA.train INFO: Epoch[2] Iteration[1800/2129], loss: 18.8965, sdm_loss: 6.9725, id_loss: 9.6799, gen_loss: 2.2440, Base Lr: 2.80e-06
2026-01-03 03:52:36,541 IRRA.train INFO: Epoch[2] Iteration[1900/2129], loss: 18.8855, sdm_loss: 6.9717, id_loss: 9.6752, gen_loss: 2.2386, Base Lr: 2.80e-06
2026-01-03 04:00:50,704 IRRA.train INFO: Epoch[2] Iteration[2000/2129], loss: 18.8743, sdm_loss: 6.9708, id_loss: 9.6695, gen_loss: 2.2340, Base Lr: 2.80e-06
2026-01-03 04:09:05,893 IRRA.train INFO: Epoch[2] Iteration[2100/2129], loss: 18.8637, sdm_loss: 6.9700, id_loss: 9.6648, gen_loss: 2.2289, Base Lr: 2.80e-06
2026-01-03 04:11:29,217 IRRA.train INFO: Epoch 2 done. Time per batch: 4.946[s] Speed: 6.5[samples/s]
2026-01-03 04:11:29,218 IRRA.train INFO: Validation Results - Epoch: 2
2026-01-03 04:13:28,703 IRRA.eval INFO: 
+------+-------+-------+-------+-------+-------+
| task |   R1  |   R5  |  R10  |  mAP  |  mINP |
+------+-------+-------+-------+-------+-------+
| t2i  | 0.162 | 0.601 | 1.088 | 0.394 | 0.199 |
+------+-------+-------+-------+-------+-------+
2026-01-03 04:21:51,126 IRRA.train INFO: Epoch[3] Iteration[100/2129], loss: 18.6601, sdm_loss: 6.9559, id_loss: 9.5565, gen_loss: 2.1477, Base Lr: 4.60e-06
2026-01-03 04:30:04,813 IRRA.train INFO: Epoch[3] Iteration[200/2129], loss: 18.6456, sdm_loss: 6.9544, id_loss: 9.5510, gen_loss: 2.1403, Base Lr: 4.60e-06
2026-01-03 04:38:18,370 IRRA.train INFO: Epoch[3] Iteration[300/2129], loss: 18.6257, sdm_loss: 6.9530, id_loss: 9.5432, gen_loss: 2.1294, Base Lr: 4.60e-06
2026-01-03 04:46:32,383 IRRA.train INFO: Epoch[3] Iteration[400/2129], loss: 18.6101, sdm_loss: 6.9517, id_loss: 9.5335, gen_loss: 2.1248, Base Lr: 4.60e-06
2026-01-03 04:54:46,838 IRRA.train INFO: Epoch[3] Iteration[500/2129], loss: 18.6020, sdm_loss: 6.9511, id_loss: 9.5266, gen_loss: 2.1243, Base Lr: 4.60e-06
2026-01-03 05:03:01,109 IRRA.train INFO: Epoch[3] Iteration[600/2129], loss: 18.5914, sdm_loss: 6.9505, id_loss: 9.5222, gen_loss: 2.1188, Base Lr: 4.60e-06
2026-01-03 05:11:15,902 IRRA.train INFO: Epoch[3] Iteration[700/2129], loss: 18.5844, sdm_loss: 6.9490, id_loss: 9.5187, gen_loss: 2.1166, Base Lr: 4.60e-06
2026-01-03 05:19:30,064 IRRA.train INFO: Epoch[3] Iteration[800/2129], loss: 18.5763, sdm_loss: 6.9487, id_loss: 9.5146, gen_loss: 2.1130, Base Lr: 4.60e-06
2026-01-03 05:27:44,400 IRRA.train INFO: Epoch[3] Iteration[900/2129], loss: 18.5712, sdm_loss: 6.9481, id_loss: 9.5118, gen_loss: 2.1113, Base Lr: 4.60e-06
2026-01-03 05:35:59,039 IRRA.train INFO: Epoch[3] Iteration[1000/2129], loss: 18.5640, sdm_loss: 6.9475, id_loss: 9.5092, gen_loss: 2.1073, Base Lr: 4.60e-06
2026-01-03 05:44:13,524 IRRA.train INFO: Epoch[3] Iteration[1100/2129], loss: 18.5600, sdm_loss: 6.9471, id_loss: 9.5064, gen_loss: 2.1065, Base Lr: 4.60e-06
2026-01-03 05:52:28,297 IRRA.train INFO: Epoch[3] Iteration[1200/2129], loss: 18.5540, sdm_loss: 6.9468, id_loss: 9.5028, gen_loss: 2.1045, Base Lr: 4.60e-06
2026-01-03 06:00:42,734 IRRA.train INFO: Epoch[3] Iteration[1300/2129], loss: 18.5509, sdm_loss: 6.9464, id_loss: 9.5006, gen_loss: 2.1038, Base Lr: 4.60e-06
2026-01-03 06:08:57,146 IRRA.train INFO: Epoch[3] Iteration[1400/2129], loss: 18.5467, sdm_loss: 6.9460, id_loss: 9.4979, gen_loss: 2.1029, Base Lr: 4.60e-06
2026-01-03 06:17:11,002 IRRA.train INFO: Epoch[3] Iteration[1500/2129], loss: 18.5418, sdm_loss: 6.9455, id_loss: 9.4951, gen_loss: 2.1011, Base Lr: 4.60e-06
2026-01-03 06:25:25,487 IRRA.train INFO: Epoch[3] Iteration[1600/2129], loss: 18.5362, sdm_loss: 6.9452, id_loss: 9.4931, gen_loss: 2.0979, Base Lr: 4.60e-06
2026-01-03 06:33:39,789 IRRA.train INFO: Epoch[3] Iteration[1700/2129], loss: 18.5330, sdm_loss: 6.9446, id_loss: 9.4915, gen_loss: 2.0968, Base Lr: 4.60e-06
2026-01-03 06:41:53,729 IRRA.train INFO: Epoch[3] Iteration[1800/2129], loss: 18.5293, sdm_loss: 6.9443, id_loss: 9.4898, gen_loss: 2.0953, Base Lr: 4.60e-06
2026-01-03 06:50:07,798 IRRA.train INFO: Epoch[3] Iteration[1900/2129], loss: 18.5253, sdm_loss: 6.9440, id_loss: 9.4881, gen_loss: 2.0931, Base Lr: 4.60e-06
2026-01-03 06:58:22,955 IRRA.train INFO: Epoch[3] Iteration[2000/2129], loss: 18.5218, sdm_loss: 6.9438, id_loss: 9.4862, gen_loss: 2.0918, Base Lr: 4.60e-06
2026-01-03 07:06:37,326 IRRA.train INFO: Epoch[3] Iteration[2100/2129], loss: 18.5182, sdm_loss: 6.9436, id_loss: 9.4836, gen_loss: 2.0909, Base Lr: 4.60e-06
2026-01-03 07:09:00,820 IRRA.train INFO: Epoch 3 done. Time per batch: 4.945[s] Speed: 6.5[samples/s]
2026-01-03 07:09:00,820 IRRA.train INFO: Validation Results - Epoch: 3
2026-01-03 07:11:00,787 IRRA.eval INFO: 
+------+-------+-------+-------+-------+-------+
| task |   R1  |   R5  |  R10  |  mAP  |  mINP |
+------+-------+-------+-------+-------+-------+
| t2i  | 0.162 | 0.617 | 1.056 | 0.401 | 0.196 |
+------+-------+-------+-------+-------+-------+
2026-01-03 07:19:18,952 IRRA.train INFO: Epoch[4] Iteration[100/2129], loss: 18.4529, sdm_loss: 6.9366, id_loss: 9.4424, gen_loss: 2.0739, Base Lr: 6.40e-06
2026-01-03 07:27:33,100 IRRA.train INFO: Epoch[4] Iteration[200/2129], loss: 18.4533, sdm_loss: 6.9331, id_loss: 9.4354, gen_loss: 2.0849, Base Lr: 6.40e-06
2026-01-03 07:35:47,265 IRRA.train INFO: Epoch[4] Iteration[300/2129], loss: 18.4468, sdm_loss: 6.9355, id_loss: 9.4372, gen_loss: 2.0741, Base Lr: 6.40e-06
2026-01-03 07:44:00,970 IRRA.train INFO: Epoch[4] Iteration[400/2129], loss: 18.4403, sdm_loss: 6.9348, id_loss: 9.4384, gen_loss: 2.0670, Base Lr: 6.40e-06
2026-01-03 07:52:15,022 IRRA.train INFO: Epoch[4] Iteration[500/2129], loss: 18.4294, sdm_loss: 6.9330, id_loss: 9.4335, gen_loss: 2.0629, Base Lr: 6.40e-06
2026-01-03 08:00:28,996 IRRA.train INFO: Epoch[4] Iteration[600/2129], loss: 18.4285, sdm_loss: 6.9326, id_loss: 9.4331, gen_loss: 2.0628, Base Lr: 6.40e-06
2026-01-03 08:08:42,844 IRRA.train INFO: Epoch[4] Iteration[700/2129], loss: 18.4239, sdm_loss: 6.9327, id_loss: 9.4318, gen_loss: 2.0594, Base Lr: 6.40e-06
2026-01-03 08:16:57,024 IRRA.train INFO: Epoch[4] Iteration[800/2129], loss: 18.4219, sdm_loss: 6.9321, id_loss: 9.4310, gen_loss: 2.0588, Base Lr: 6.40e-06
2026-01-03 08:25:10,700 IRRA.train INFO: Epoch[4] Iteration[900/2129], loss: 18.4172, sdm_loss: 6.9312, id_loss: 9.4303, gen_loss: 2.0556, Base Lr: 6.40e-06
2026-01-03 08:33:24,748 IRRA.train INFO: Epoch[4] Iteration[1000/2129], loss: 18.4146, sdm_loss: 6.9308, id_loss: 9.4294, gen_loss: 2.0544, Base Lr: 6.40e-06
2026-01-03 08:41:38,987 IRRA.train INFO: Epoch[4] Iteration[1100/2129], loss: 18.4120, sdm_loss: 6.9303, id_loss: 9.4277, gen_loss: 2.0540, Base Lr: 6.40e-06
2026-01-03 08:49:53,061 IRRA.train INFO: Epoch[4] Iteration[1200/2129], loss: 18.4080, sdm_loss: 6.9297, id_loss: 9.4267, gen_loss: 2.0516, Base Lr: 6.40e-06
2026-01-03 08:58:08,289 IRRA.train INFO: Epoch[4] Iteration[1300/2129], loss: 18.4059, sdm_loss: 6.9289, id_loss: 9.4263, gen_loss: 2.0507, Base Lr: 6.40e-06
2026-01-03 09:06:22,207 IRRA.train INFO: Epoch[4] Iteration[1400/2129], loss: 18.4035, sdm_loss: 6.9288, id_loss: 9.4244, gen_loss: 2.0503, Base Lr: 6.40e-06
2026-01-03 09:14:36,664 IRRA.train INFO: Epoch[4] Iteration[1500/2129], loss: 18.4025, sdm_loss: 6.9280, id_loss: 9.4241, gen_loss: 2.0504, Base Lr: 6.40e-06
2026-01-03 09:22:50,896 IRRA.train INFO: Epoch[4] Iteration[1600/2129], loss: 18.3992, sdm_loss: 6.9274, id_loss: 9.4229, gen_loss: 2.0489, Base Lr: 6.40e-06
2026-01-03 09:31:05,476 IRRA.train INFO: Epoch[4] Iteration[1700/2129], loss: 18.3965, sdm_loss: 6.9264, id_loss: 9.4220, gen_loss: 2.0482, Base Lr: 6.40e-06
2026-01-03 09:39:23,046 IRRA.train INFO: Epoch[4] Iteration[1800/2129], loss: 18.3954, sdm_loss: 6.9263, id_loss: 9.4214, gen_loss: 2.0477, Base Lr: 6.40e-06
2026-01-03 09:47:39,774 IRRA.train INFO: Epoch[4] Iteration[1900/2129], loss: 18.3928, sdm_loss: 6.9257, id_loss: 9.4205, gen_loss: 2.0466, Base Lr: 6.40e-06
2026-01-03 09:55:56,916 IRRA.train INFO: Epoch[4] Iteration[2000/2129], loss: 18.3914, sdm_loss: 6.9250, id_loss: 9.4201, gen_loss: 2.0463, Base Lr: 6.40e-06
2026-01-03 10:04:15,255 IRRA.train INFO: Epoch[4] Iteration[2100/2129], loss: 18.3898, sdm_loss: 6.9245, id_loss: 9.4197, gen_loss: 2.0455, Base Lr: 6.40e-06
2026-01-03 10:06:39,419 IRRA.train INFO: Epoch 4 done. Time per batch: 4.950[s] Speed: 6.5[samples/s]
2026-01-03 10:06:39,420 IRRA.train INFO: Validation Results - Epoch: 4
2026-01-03 10:08:40,452 IRRA.eval INFO: 
+------+-------+-------+-------+-------+-------+
| task |   R1  |   R5  |  R10  |  mAP  |  mINP |
+------+-------+-------+-------+-------+-------+
| t2i  | 0.097 | 0.666 | 1.170 | 0.416 | 0.205 |
+------+-------+-------+-------+-------+-------+
2026-01-03 10:16:59,978 IRRA.train INFO: Epoch[5] Iteration[100/2129], loss: 18.3435, sdm_loss: 6.9116, id_loss: 9.3979, gen_loss: 2.0340, Base Lr: 8.20e-06
2026-01-03 10:25:14,830 IRRA.train INFO: Epoch[5] Iteration[200/2129], loss: 18.3342, sdm_loss: 6.9081, id_loss: 9.3972, gen_loss: 2.0289, Base Lr: 8.20e-06
2026-01-03 10:33:29,905 IRRA.train INFO: Epoch[5] Iteration[300/2129], loss: 18.3311, sdm_loss: 6.9079, id_loss: 9.3989, gen_loss: 2.0243, Base Lr: 8.20e-06
2026-01-03 10:41:45,245 IRRA.train INFO: Epoch[5] Iteration[400/2129], loss: 18.3289, sdm_loss: 6.9064, id_loss: 9.4003, gen_loss: 2.0221, Base Lr: 8.20e-06
2026-01-03 10:50:00,991 IRRA.train INFO: Epoch[5] Iteration[500/2129], loss: 18.3300, sdm_loss: 6.9054, id_loss: 9.3988, gen_loss: 2.0258, Base Lr: 8.20e-06
2026-01-03 10:58:16,718 IRRA.train INFO: Epoch[5] Iteration[600/2129], loss: 18.3234, sdm_loss: 6.9020, id_loss: 9.3982, gen_loss: 2.0232, Base Lr: 8.20e-06
2026-01-03 11:06:33,432 IRRA.train INFO: Epoch[5] Iteration[700/2129], loss: 18.3223, sdm_loss: 6.9001, id_loss: 9.3974, gen_loss: 2.0248, Base Lr: 8.20e-06
