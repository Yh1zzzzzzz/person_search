MLM: false
alpha: 0.9
amp: true
amp_dtype: bf16
attn_implementation: sdpa
backbone: t5gemma2_vion_tower
batch_size: 32
beta: 0.999
bias_lr_factor: 2.0
bnneck: true
classifier_lr: 3.0e-05
cmt_depth: 4
dataset_name: CUHK-PEDES
distributed: false
eval_period: 1
gamma: 0.1
gen_loss_weight: 0.0
gen_prompt: Caption
gen_prompt_length: 32
grad_accum_steps: 1
gradient_checkpointing: true
hf_model_name_or_path: T5_270M_Base
id_loss_weight: 1
img_aug: true
img_size: !!python/tuple
- 384
- 128
local_rank: 0
log_period: 100
loss_names: sdm+id
lr: 1.0e-06
lr_factor: 5.0
lrscheduler: cosine
masked_token_rate: 0.8
masked_token_unchanged_rate: 0.1
max_grad_norm: 0.0
milestones: !!python/tuple
- 20
- 50
mlm_loss_weight: 1.0
mm_max_length: 512
momentum: 0.9
name: t5_vion_align_mlp_bnneck_cls1e4
num_epoch: 60
num_instance: 4
num_workers: 12
optimizer: Adam
output_dir: logs/CUHK-PEDES/20260106_234557_t5_vion_align_mlp_bnneck_cls1e4
power: 0.9
pretrain_choice: ViT-B/16
projector_lr: 3.0e-05
resume: false
resume_ckpt_file: ''
reuse_mm_encoder_for_image: false
root_dir: training_data
sampler: random
stride_size: 16
target_lr: 0
temperature: 0.02
test_batch_size: 512
text_length: 77
tokenizers_parallelism: 'false'
training: true
val_dataset: test
vocab_size: 49408
warmup_epochs: 5
warmup_factor: 0.1
warmup_method: linear
weight_decay: 0.0001
weight_decay_bias: 0.0
